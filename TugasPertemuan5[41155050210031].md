## TUGAS 5
Nama: Sifa Maryam Rahman<br>
NPM:	41155050210031<br>
Kelas:	TIF A1

1. Berikut adalah hasil praktik dari video youtube https://youtu.be/4zARMcgc7hA?si=x6RoHQXFF4NY76X8   

	 1.1 Persiapan sample dataset

   ![image](https://github.com/user-attachments/assets/4b1e3930-d8b5-428c-9ec9-e47ef400e15b)

	 1.2 Visualisasi dataset
 
   ![image](https://github.com/user-attachments/assets/4d54de92-3b74-4e2a-be09-a1c4003bcd6d)
   ![image](https://github.com/user-attachments/assets/9a4029de-7451-4b8e-bca3-a38f65bb1e2e)

	 1.3 Pengantar classification dengan K-Nearest Neighbours | KNN

   1.4 Preprocessing dataset dengan Label Binarizer

   ![image](https://github.com/user-attachments/assets/7a013906-598b-4927-8801-6c223cd18f62)

 
	 1.5 Training KNN Classification Model
   ![image](https://github.com/user-attachments/assets/77e43dc3-16ce-4c70-b204-84842a5403ab)

   1.6 Prediksi dengan KNN Classification Model

   ![image](https://github.com/user-attachments/assets/cb0184bc-88e1-4471-b7bb-428a1799767a)

	 1.7 Visualisasi Nearest Neighbours
 
   ![image](https://github.com/user-attachments/assets/298e4d2f-1fdd-46cd-a8a7-cc25e32f3cf2)
   ![image](https://github.com/user-attachments/assets/1f5f57a1-85c4-4a43-9975-b70553b2d0fb)

 
	 1.8 Kalkulasi jarak dengan Euclidean Distance
   
   ![image](https://github.com/user-attachments/assets/c0e377ff-90e3-4845-ac5a-0573fbcfaca4)
   ![image](https://github.com/user-attachments/assets/88035fa0-64f8-4824-ae76-bca66c2a0a48)
   ![image](https://github.com/user-attachments/assets/f551a114-9b7f-460e-840a-4b06dead858b)
 
	 1.9 Evaluasi KNN Classification Model | Persiapan testing set
   
   ![image](https://github.com/user-attachments/assets/ae1baf43-3494-44e0-b275-79a3389b2faf)

	 1.10 Evaluasi model dengan accuracy score
   
   ![image](https://github.com/user-attachments/assets/43725e03-e7bd-4309-9e41-ac8631b48490)

	 1.11 Evaluasi model dengan precision score

   ![image](https://github.com/user-attachments/assets/e820e924-6b1d-49e4-8ccc-e971460e9e4a)

	 1.12 Evaluasi model dengan recall score

   ![image](https://github.com/user-attachments/assets/498fa9f5-109c-474e-bddc-85cbf008f28c)

	 1.13 Evaluasi model dengan F1 score

   ![image](https://github.com/user-attachments/assets/0e8c7b83-8087-4f41-8ab0-a1d2389258ca)

   1.14 Evaluasi model dengan classification report

   ![image](https://github.com/user-attachments/assets/0b2e26e4-e17f-40aa-a466-9e6d6f5d796e)

   1.15 Evaluasi model dengan Mathews Correlation Coefficient
   
   ![image](https://github.com/user-attachments/assets/b7346cc7-c976-4843-9a1c-4774a9dc8b22)

 
 2. Berikut adalah hasil praktik dari video youtube https://youtu.be/z69XYXpvVrE?si=KR_hDSlwjGIMcT0w
 
 2.1 Pengenalan Decision Boundary & Hyperplane
    
##Decision Boundary (Hyperplane)

![image](https://github.com/user-attachments/assets/10f565a0-92a6-4734-882e-759209f77a39)

Gambar ini menunjukkan ilustrasi sederhana dari decision boundary (batas keputusan) atau hyperplane yang digunakan dalam klasifikasi pembelajaran mesin, khususnya dalam ruang dua dimensi dengan sumbu yang dilabeli X1 dan X2. Dua set data, yang direpresentasikan dengan lingkaran hitam dan putih, mewakili dua kelas yang berbeda. 

Berikut penjelasan dari masing-masing hyperplane:
	
  - H1 (Garis Hijau) - Hyperplane ini adalah salah satu kemungkinan batas antara dua kelas. Namun, posisinya sangat dekat dengan titik-titik hitam, yang berarti tidak memberikan margin yang cukup besar di antara kedua kelas. Dalam klasifikasi, batas keputusan seperti ini mungkin tidak ideal karena bisa menyebabkan kesalahan klasifikasi jika data sedikit bervariasi.<BR>
  - H2  (Garis Biru) - Hyperplane ini mewakili batas yang lebih baik yang memaksimalkan margin, sehingga menjadi optimal hyperplane dalam konteks support vector machine (SVM). SVM bertujuan untuk menemukan hyperplane yang memaksimalkan margin ini untuk meningkatkan akurasi dan ketahanan dalam klasifikasi.<BR>
  - H3  (Garis Merah) - Hyperplane ini tidak memisahkan dua kelas dengan baik karena memotong kedua lingkaran hitam dan putih. Jika digunakan sebagai batas keputusan, ini akan menyebabkan kesalahan klasifikasi.<BR>

Secara keseluruhan, dari ketiga pilihan ini, H2 adalah optimal hyperplane karena memaksimalkan margin antara dua kelas, yang merupakan prinsip utama dalam klasifikasi SVM.

2.2 Pengenalan Support Vector & Maximum Margin

Vector & Maximum Margin


![image](https://github.com/user-attachments/assets/438456e0-26a1-4cfb-92f9-b670349c89a0)

Gambar ini menunjukkan konsep Maximum Margin dalam Support Vector Machine (SVM) pada ruang dua dimensi dengan sumbu x1 dan x2. SVM adalah algoritma pembelajaran mesin yang digunakan untuk klasifikasi, dan tujuannya adalah untuk menemukan hyperplane (batas keputusan) yang memisahkan dua kelas dengan margin maksimum.

Berikut penjelasan elemen-elemen penting dalam gambar:
    
1. yperplane (garis merah, w. x – b = 0) - Garis ini adalah decision boundary atau batas keputusan yang memisahkan            dua kelas (titik biru dan titik hijau). Dalam SVM, hyperplane ini ditentukan oleh persamaan w. x – b = 0
	
2. Support Vectors (titik biru dan hijau di garis putus-putus) - Titik-titik ini adalah data terdekat dari masing-            masing kelas ke hyperplane. Mereka disebut support vectors dan memiliki pengaruh langsung dalam menentukan posisi          hyperplane. Dalam gambar, beberapa titik biru dan satu titik hijau berfungsi sebagai support vectors.
 
3. Margin Maksimum (daerah berwarna kuning) - Margin maksimum adalah jarak antara garis putus-putus (di atas dan di           bawah hyperplane) yang melewati support vectors dari kedua kelas. Dalam SVM, kita berusaha memaksimalkan jarak             ini agar model lebih akurat dan memiliki ketahanan terhadap perubahan data. Margin ini berukuran 2/(||w||)
    
4. Garis Batas (garis putus-putus) - Garis-garis ini memiliki persamaan w. x – b = 1 dan w. x – b = -1, dan menandai          batas margin maksimum. Setiap titik yang berada di luar atau di tepi margin maksimum dianggap sebagai anggota              kelas masing-masing.

Inti dari konsep ini adalah memilih hyperplane yang memberikan margin terbesar antara dua kelas, yang membuat model lebih andal dan lebih tahan terhadap kesalahan klasifikasi pada data baru.
	
2.3 Pengenalan kondisi Linearly Inseparable dan Kernel Tricks

Linearly Inseparable dan Kernel Tricks

![image](https://github.com/user-attachments/assets/740451e7-83fb-4ab7-b754-c9c7b37dbb55)

Gambar ini menjelaskan konsep data yang linearly inseparable (tidak dapat dipisahkan secara linear) dan bagaimana kernel trick dapat membantu dalam kasus tersebut. Konsep ini sering digunakan dalam Support Vector Machine (SVM) untuk menangani data yang tidak dapat dipisahkan dengan garis lurus atau hyperplane dalam ruang dua dimensi.

Berikut penjelasan mengenai gambar:
1.  Gambar Kiri (Data Tidak Dapat Dipisahkan secara Linear):
    Di gambar ini, terdapat dua kelompok data, yang ditandai dengan titik hitam dan tanda silang biru, yang tidak dapat        dipisahkan dengan garis lurus dalam ruang dua dimensi. Jika kita mencoba menggambar garis lurus di antara kedua            kelompok ini, kita tidak akan bisa memisahkan keduanya secara sempurna. Masalah seperti ini disebut sebagai linearly       inseparable.

2. Gambar Kanan (Penggunaan Kernel Trick untuk Meningkatkan Dimensi):
	 - Untuk mengatasi masalah linearly inseparable, digunakan kernel trick. Dengan kernel trick, kita mentransformasikan         data ke dimensi yang lebih tinggi, sehingga data yang sebelumnya tidak dapat dipisahkan menjadi mungkin untuk     dipisahkan.
	 - Di gambar ini, data diubah dari dua dimensi menjadi tiga dimensi, yang memungkinkan pemisahan antara dua kelompok          data menggunakan sebuah hyperplane (atau bidang dalam tiga dimensi). Dalam ruang tiga dimensi, kita bisa menarik b         bidang pemisah di antara dua kelompok data ini, yang sebelumnya tidak mungkin di ruang dua dimensi.

## Inti dari Kernel Trick

Kernel trick memungkinkan model untuk bekerja di ruang berdimensi tinggi tanpa harus benar-benar menghitung koordinat data dalam dimensi tersebut. Ini dilakukan dengan menggunakan fungsi kernel untuk menghitung jarak antara titik data secara tidak langsung. Beberapa fungsi kernel yang populer adalah linear kernel, polynomial kernel, dan radial basis function (RBF) kernel.

Dalam konteks SVM, kernel trick sangat berguna karena memungkinkan kita memisahkan data yang tidak dapat dipisahkan secara linear dalam dimensi yang lebih rendah.
 
2.4 Pengenalan MNIST Handwritten Digits Dataset
 
![image](https://github.com/user-attachments/assets/66f51d1d-7e3b-4f3b-a8ec-a43117111592)

![image](https://github.com/user-attachments/assets/2e1b79a5-daec-43a6-86e8-ab5868b9af19)

 
2.5 Klasifikasi dengan Support Vector Classifier | SVC

![image](https://github.com/user-attachments/assets/e27ea5cc-494c-43a3-949e-0cde0f05dd6e)

2.6 Hyperparameter Tuning dengan Grid Search

![image](https://github.com/user-attachments/assets/a42e2213-2cdb-4178-8b48-f7c438a448a8)

![image](https://github.com/user-attachments/assets/6ca93b98-f161-4528-b932-4db415807c1d)

![image](https://github.com/user-attachments/assets/49b991a3-09dd-44ec-bd78-4549985bbd54)

2.7 Evaluasi Model

![image](https://github.com/user-attachments/assets/6b09ae5f-e350-4c89-b3c4-94aa68cb65fb)
